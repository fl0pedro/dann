{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from itertools import cycle\n",
    "import colorsys\n",
    "import re\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"all_test_results.pkl\", \"rb\") as f:\n",
    "    all_test_results: pd.DataFrame = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_n = 2\n",
    "all_test_results[\"trainable_params_grouped\"] = grouped_n ** np.round(np.log(all_test_results[\"trainable_params\"]) / np.log(grouped_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max(x):\n",
    "  return x.min(), x.max()\n",
    "\n",
    "group_keys = [\"dataset\", \"type\", \"model\", \"trainable_params_grouped\"]\n",
    "\n",
    "stats = (\n",
    "    all_test_results\n",
    "    .groupby(group_keys, as_index=False)\n",
    "    .agg(min=(\"test_acc\", \"min\"),\n",
    "         max=(\"test_acc\", \"max\"),\n",
    "         test_acc=(\"test_acc\", \"mean\"),\n",
    "         std=(\"test_acc\", \"std\"))\n",
    ")\n",
    "\n",
    "max_points = (\n",
    "    all_test_results\n",
    "    .loc[all_test_results.groupby(group_keys[:-1])[\"test_acc\"].idxmax()]\n",
    "    .assign(max_type=\"max_point\")\n",
    ")\n",
    "\n",
    "max_mean_points = (\n",
    "    stats\n",
    "    .loc[stats.groupby(group_keys[:-1])[\"test_acc\"].idxmax()]\n",
    "    .assign(max_type=\"max_mean_point\")\n",
    ")\n",
    "\n",
    "def to_percent(key: str):\n",
    "  def f(x: pd.Series):\n",
    "    return x[key].map(\"{:.2%}\".format)\n",
    "  return f\n",
    "\n",
    "max_values = (\n",
    "  pd.concat([max_points, max_mean_points])\n",
    "    .set_index([\"dataset\", \"type\", \"max_type\"])\n",
    "    .sort_values(\"test_acc\", ascending=False)\n",
    "    .sort_index(level=[\"dataset\", \"type\", \"max_type\"])\n",
    "    .assign(test_acc_percent=to_percent(\"test_acc\"), std_percent=to_percent(\"std\"))\n",
    ")\n",
    "\n",
    "stats.set_index([\"dataset\", \"type\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_results[(all_test_results[[\"dataset\", \"type\"]] == (\"cifar10\", \"dropout\")).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opt import get_model_idx\n",
    "get_model_idx(\"dend_ann_local_rfs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = \"\"\n",
    "for dt, data in all_test_results.groupby([\"dataset\", \"type\"]):\n",
    "    new_data = {}\n",
    "    for k, v in data.groupby([\"model\", \"num_dends\", \"num_soma\", \"sigma\", \"num_epochs_min\"]):\n",
    "        if len(v) == 5:\n",
    "            d = dict(\n",
    "                acc_mean=v[\"test_acc\"].mean(),\n",
    "                acc_std=v[\"test_acc\"].std(),\n",
    "                loss_mean=v[\"test_loss\"].mean(),\n",
    "                loss_std=v[\"test_loss\"].std()\n",
    "            )\n",
    "            new_data[k] = d\n",
    "    print(*dt, sep=\" - \")\n",
    "    new_data = (\n",
    "        pd.DataFrame(new_data).T\n",
    "        .sort_values(\"acc_mean\", ascending=False)\n",
    "        .reset_index(names=[\"model\", \"num_dends\", \"num_soma\", \"sigma\", \"num_epochs_min\"])\n",
    "    )\n",
    "    display(new_data[:10])\n",
    "    for i, row in new_data[:10].iterrows():\n",
    "        if \"dropout\" in row[\"model\"]:\n",
    "            model = \"_\".join(row[\"model\"].split(\"_\")[:-2])\n",
    "        else:\n",
    "            model = row[\"model\"]\n",
    "        out += f\"seq 5 | xargs -I [] uv run main.py --trial [] --model {get_model_idx(model)} --dataset {dt[0]} --num-layers 2 --sigma {row['sigma']} -d {row['num_dends']} -s {row['num_soma']} -o best_test --backend tensorflow &\\n\"\n",
    "\n",
    "print(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for dt, data in all_test_results.groupby([\"dataset\", \"type\"]):\n",
    "  keys = all_test_results[\"model\"].unique()\n",
    "  colors = dict(zip(keys, sns.color_palette(\"husl\", len(keys))))\n",
    "\n",
    "  if dt[1] == \"other_fmnist\":\n",
    "    continue\n",
    "\n",
    "  fig, ax = plt.subplots()\n",
    "\n",
    "  sns.lineplot(data, x=\"trainable_params_grouped\", y=\"test_acc\", hue=\"model\", errorbar=\"sd\", palette=colors)\n",
    "  sns.lineplot(stats.loc[dt], x=\"trainable_params_grouped\", y=\"min\", hue=\"model\", linestyle=\"--\", alpha=0.25, legend=False, palette=colors)\n",
    "  sns.lineplot(stats.loc[dt], x=\"trainable_params_grouped\", y=\"max\", hue=\"model\", linestyle=\"--\", alpha=0.25, legend=False, palette=colors)\n",
    "  sns.scatterplot(data=max_values.loc[*dt, \"max_point\"], x=\"trainable_params\", y=\"test_acc\", hue=\"model\", palette=colors, legend=False, marker=\"X\")\n",
    "  sns.scatterplot(data=max_values.loc[*dt, \"max_mean_point\"], x=\"trainable_params_grouped\", y=\"test_acc\", hue=\"model\", palette=colors, legend=False, marker=\"*\", s=125)\n",
    "  \n",
    "  plt.xscale(\"log\")\n",
    "  ax.yaxis.set_major_formatter(PercentFormatter(xmax=1.0))\n",
    "  plt.title('\\n'.join(dt))\n",
    "  \n",
    "  plt.show()\n",
    "\n",
    "  print(\n",
    "    \" - \".join(dt), \"\",\n",
    "    \"max points:\", \n",
    "    max_values[[\"model\",\"test_acc_percent\", \"trainable_params\"]]\n",
    "      .loc[(*dt, \"max_point\")]\n",
    "      .reset_index(drop=True)\n",
    "      .to_string(),\n",
    "    \"\\nmax mean points:\", \n",
    "    max_values[[\"model\", \"test_acc_percent\", \"trainable_params_grouped\", \"std_percent\"]]\n",
    "      .loc[(*dt, \"max_mean_point\")]\n",
    "      .reset_index(drop=True)\n",
    "      .to_string(),\n",
    "    sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = all_test_results[all_test_results[\"file_name\"] == \"fmnist_1_layer_noise.png\"]\n",
    "# TODO: don't forget to look at the noise graph ^ low priority but WIP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import num_trainable_params\n",
    "from opt import make_masks, get_ordered_model_names\n",
    "from main import update_model_config\n",
    "from collections import namedtuple\n",
    "\n",
    "# for i in range(2, 5):\n",
    "#     for j in range(2, 5):\n",
    "# print(i,j)\n",
    "i, j = 1, 2\n",
    "num_dendrites = 4**i\n",
    "num_somas = 4**j\n",
    "# print(2**i,2**j)\n",
    "num_layers = 2\n",
    "synapses = 16 # doesn't do shit\n",
    "img_width = 28\n",
    "img_height = 28\n",
    "num_classes = 10\n",
    "channels = 1\n",
    "seed = 7\n",
    "\n",
    "dends = [num_dendrites]*num_layers\n",
    "somas = [num_somas]*num_layers\n",
    "\n",
    "m = namedtuple(\"modelConfig\", [\"conventional\", \"rfs\", \"model\", \"all_to_all\", \"sparse\"])\n",
    "m.conventional = False\n",
    "m.rfs = None\n",
    "m.all_to_all = False\n",
    "m.sparse = False\n",
    "m.model = 1\n",
    "\n",
    "update_model_config(m)\n",
    "\n",
    "name = get_ordered_model_names()[m.model]\n",
    "print(name)\n",
    "\n",
    "masks = make_masks(\n",
    "    dends, somas, synapses, num_layers, img_width, img_height, num_classes, channels, m.conventional, m.rfs is not None, m.rfs, name, seed\n",
    ")\n",
    "\n",
    "shift = 1\n",
    "new_order = [3-(x-shift)%4 for x in range(4)]\n",
    "axes = [m//2 for m in new_order]\n",
    "# reshaped_masks = [\n",
    "#     m.reshape(\n",
    "#         [int(np.sqrt(m.shape[i])) for i in axes]\n",
    "#     ).transpose(new_order)\n",
    "#     if m.ndim == 2 else \n",
    "#     m.reshape(\n",
    "#         int(np.sqrt(m.shape[0])), \n",
    "#         int(np.sqrt(m.shape[0]))\n",
    "#     ) for m in masks[:-2] \n",
    "# ]\n",
    "t2 = [(x.shape, x.sum().tolist()) for x in masks]\n",
    "t3 = [int(np.prod(x)) for x, _ in t2]\n",
    "t4 = [x+y for x, y in zip(t3[::2], t3[1::2])]\n",
    "\n",
    "# print([y for x, y in t2])\n",
    "# tt = [0,4**(j+i),4**(j+i),4**j]*num_layers+[4**j*num_classes, num_classes, 0]\n",
    "# print(tt)\n",
    "# tt = (4**(j+i),4**j,)*2\n",
    "# print([tt[s:e] for s,e in [(0,2),(0,4),(2,4)]])\n",
    "print(*t2, sep='\\n')\n",
    "# print([y for x, y in t2])\n",
    "# print(t3)\n",
    "# print(t4)\n",
    "# print(sum(tt))\n",
    "# print(sum(mask.sum() for mask in masks))\n",
    "print(num_trainable_params(num_dendrites, num_somas, img_width*img_height*channels, synapses, num_classes, num_layers, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, t in enumerate(masks):\n",
    "    count = 0\n",
    "    if t.ndim == 1:\n",
    "        plt.imshow(t[:,np.newaxis])\n",
    "    else:\n",
    "        plt.imshow(t)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, t in enumerate(reshaped_masks):\n",
    "    count = 0\n",
    "    if i % 4 == 0:\n",
    "        continue\n",
    "    if i % 2 == 0:\n",
    "        for i in range(t.shape[2]):\n",
    "            for j in range(t.shape[3]):\n",
    "                # count += (t[:,:,i,j].any())\n",
    "                plt.imshow(t[:,:,i,j])\n",
    "                plt.show()\n",
    "    else:\n",
    "        plt.imshow(t)\n",
    "        plt.show()\n",
    "    print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model: \"dend_ann_random\"\n",
    "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
    "┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
    "│ input (InputLayer)                   │ (None, 784)                 │               0 │\n",
    "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
    "│ dend_1 (Dense)                       │ (None, 64)                  │          50,240 │\n",
    "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
    "│ dend_1_relu (ReLU)                   │ (None, 64)                  │               0 │\n",
    "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
    "│ soma_1 (Dense)                       │ (None, 16)                  │           1,040 │\n",
    "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
    "│ soma_1_relu (ReLU)                   │ (None, 16)                  │               0 │\n",
    "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
    "│ dend_2 (Dense)                       │ (None, 64)                  │           1,088 │\n",
    "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
    "│ dend_2_relu (ReLU)                   │ (None, 64)                  │               0 │\n",
    "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
    "│ soma_2 (Dense)                       │ (None, 16)                  │           1,040 │\n",
    "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
    "│ soma_2_relu (ReLU)                   │ (None, 16)                  │               0 │\n",
    "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
    "│ output (Dense)                       │ (None, 10)                  │             170 │\n",
    "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import keras\n",
    "from masked_dense import MaskedDense\n",
    "\n",
    "p = \"all_out_2/results_mnist_2_layer/\"\n",
    "models = {}\n",
    "m = namedtuple(\"modelConfig\", [\"conventional\", \"rfs\", \"model\", \"all_to_all\", \"sparse\"])\n",
    "\n",
    "for d in os.listdir(p):\n",
    "    ms = os.listdir(p+d)\n",
    "    models.setdefault(d, {})\n",
    "    models[d][\"untrained\"] = keras.models.load_model(p+d+\"/\"+ms[0], custom_objects={'MaskedDense': MaskedDense})\n",
    "    models[d][\"trained\"] = keras.models.load_model(p+d+\"/\"+ms[1], custom_objects={'MaskedDense': MaskedDense})\n",
    "\n",
    "from typing import Callable, Iterable\n",
    "def pp(x: Iterable, n: int | list[int]):\n",
    "    if isinstance(n, int):\n",
    "        print(' | '.join([f\"{k}{' '*(n-len(str(k)))}\" for k in x]))\n",
    "    else:\n",
    "        print(' | '.join([f\"{k}{' '*(m-len(str(k)))}\" for m, k in zip(n,x)]))\n",
    "\n",
    "for i in range(12):\n",
    "    m.conventional = False\n",
    "    m.rfs = None\n",
    "    m.all_to_all = False\n",
    "    m.sparse = False\n",
    "    m.model = i\n",
    "    update_model_config(m)\n",
    "    name = get_ordered_model_names()[i]\n",
    "    masks = make_masks(\n",
    "        dends, somas, synapses, num_layers, img_width, img_height, num_classes, channels, m.conventional, m.rfs is not None, m.rfs, name, seed\n",
    "    )\n",
    "\n",
    "    W1 = models[name][\"untrained\"].weights\n",
    "    W2 = models[name][\"trained\"].weights\n",
    "    # t2 = [f\"shape={x.shape}; params={x.sum().tolist()}\" for x in masks]\n",
    "    # print([int((abs(w2-w1)>0).numpy().sum()) for x, w1, w2 in zip(W1, W2)])\n",
    "    pp([name]+[f\"{int(x.sum())} vs {int((w1!=w2).numpy().sum())}\" for x, w1, w2 in zip(masks, W1, W2)], [22,14,8,12,8,12,8,12,8,11,5])\n",
    "    # print((np.abs(w1-w2) > 0).sum())\n",
    "\n",
    "pp([\"shapes\"]+[x.shape for x in masks], [22,14,8,12,8,12,8,12,8,11,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = models[get_ordered_model_names()[1]][\"untrained\"].weights\n",
    "w2 = models[get_ordered_model_names()[1]][\"trained\"].weights\n",
    "\n",
    "print((abs(w1[0]-w2[0])>0).numpy().sum())\n",
    "print((abs(w2[1]-w1[1])>0).numpy().sum())\n",
    "print((abs(w1[2]-w2[2])>0).numpy().sum())\n",
    "print((abs(w1[4]-w2[4])>0).numpy().sum())\n",
    "print((abs(w1[6]-w2[6])>0).numpy().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from receptive_fields import *\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "def make_masks_local(\n",
    "    dends, soma, synapses, num_layers, img_width, img_height,\n",
    "    num_classes=10, channels=1, conventional=False, sparse=False,\n",
    "    rfs=True, rfs_type='somatic', rfs_mode='random',\n",
    "    input_sample=None, seed=None, *, np=np\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Make masks to transform a traditional ANN in a dendritic ANN.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dends : list\n",
    "        Number of dendrites/soma per layer.\n",
    "    soma : list\n",
    "        Number of somata per layer.\n",
    "    num_layers : int\n",
    "        Number of dendrosomatic layers.\n",
    "    img_width : int\n",
    "        The width of the input images.\n",
    "    img_height : int\n",
    "        The height of the input images.\n",
    "    channels : int\n",
    "        The number of channels of the input images.\n",
    "    conventional : boolean\n",
    "        If the model is of all-to-all type (True) or not (False).\n",
    "        Default is False.\n",
    "    sparse : boolean\n",
    "        If the model is of random (True) or structured (False) sparse\n",
    "        connections. Default is False.\n",
    "    rfs : boolean\n",
    "        If the model is of RFs (True) or random (False) structured connections.\n",
    "        Default is True.\n",
    "    rfs_type : str\n",
    "        Type of RFs; local (`dendritic`) or global (`somatic`).\n",
    "        Default is `somatic`.\n",
    "    rfs_mode : str\n",
    "        Mode of rfs construction. Default is `random`. Other valid options\n",
    "        are `one_to_one` and `constant`. Refer to receptive_fields.py in\n",
    "        random_connectivity function for more information.\n",
    "    np : Callable, optional\n",
    "        Numpy like backend (e.g. numpy vs jax.numpy)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    masks : list\n",
    "        A list with np.ndarrays containing the boolean masks for all layer\n",
    "        weights and biases.\n",
    "\n",
    "    \"\"\"\n",
    "    masks = []\n",
    "    for i in range(num_layers):\n",
    "        if i == 0:\n",
    "            # first layer --> create a matrix with input dimensions.\n",
    "            matrix = np.zeros((img_width, img_height))\n",
    "        else:\n",
    "            # for the rest dendrosomatic layers the input is a `square` form of\n",
    "            # the previous layer's somata.\n",
    "            divisors = [j for j in range(1, soma[i-1] + 1) if soma[i-1] % j == 0]\n",
    "            ix = len(divisors) // 2\n",
    "            if len(divisors) % 2 == 0:\n",
    "                matrix = np.zeros((divisors[ix], divisors[ix - 1]))\n",
    "            else:\n",
    "                matrix = np.zeros((divisors[ix], divisors[ix]))\n",
    "\n",
    "        # when RFs are enabled!\n",
    "        print(rfs is not None, rfs_mode)\n",
    "        if rfs:\n",
    "            print(\"shape:\", matrix.shape)\n",
    "            mask_s_d, centers = receptive_fields(\n",
    "                matrix, somata=soma[i],\n",
    "                dendrites=dends[i],\n",
    "                num_of_synapses=synapses,\n",
    "                opt=rfs_mode,\n",
    "                rfs_type=rfs_type,\n",
    "                prob=0.7,\n",
    "                num_channels=channels if i == 0 else 1,\n",
    "                seed=seed\n",
    "            )\n",
    "            c = list(zip(*centers))\n",
    "            sns.scatterplot(x=c[0], y=c[1])\n",
    "            plt.show()\n",
    "            plt.imshow(mask_s_d)\n",
    "            plt.show()\n",
    "        else:\n",
    "            # if no RFs are enabled use random connectivity (like `sparse`)\n",
    "            inputs_size = matrix.size\n",
    "            factor = channels if i == 0 else 1\n",
    "\n",
    "            # for soma to the next dendrites (if more than two layers)\n",
    "            mask_s_d = random_connectivity(\n",
    "                inputs=inputs_size*factor,\n",
    "                outputs=soma[i]*dends[i],\n",
    "                conns=synapses*soma[i]*dends[i],\n",
    "                seed=seed,\n",
    "            )\n",
    "            plt.imshow(mask_s_d)\n",
    "            plt.show()\n",
    "        masks.append(mask_s_d)\n",
    "        # create a mask with `ones` for biases\n",
    "        masks.append(np.ones((mask_s_d.shape[1], )).astype('int'))\n",
    "        # Create structured connectivity if not `sparse`,\n",
    "        # else random (i.e., sparse).\n",
    "        if not sparse:\n",
    "            mask_d_s = connectivity(\n",
    "                inputs=dends[i]*soma[i],\n",
    "                outputs=soma[i]\n",
    "            )\n",
    "        else:\n",
    "            mask_d_s = random_connectivity(\n",
    "                inputs=dends[i]*soma[i],\n",
    "                outputs=soma[i],\n",
    "                conns=dends[i]*soma[i],\n",
    "                seed=seed,\n",
    "            )\n",
    "        plt.imshow(mask_d_s)\n",
    "        plt.show()\n",
    "        # Append the masks\n",
    "        masks.append(mask_d_s)\n",
    "        # create a mask with `ones` for biases\n",
    "        masks.append(np.ones((mask_d_s.shape[1], )).astype('int'))\n",
    "\n",
    "    # If vanilla ANN --> re-write the masks with ones\n",
    "    # for vanilla ANN all-to-all connectivity and RFs\n",
    "    if conventional:\n",
    "        if rfs or sparse:\n",
    "            # vanilla ANN with random, sparse inputs, or RFs\n",
    "            for i, m in enumerate(masks):\n",
    "                # `4` denotes the number of masks per dendrosomatic layer\n",
    "                # So, elements 0, 4, 8, 12, etc will have the masks defined above.\n",
    "                # All other layers will have masks filled with ones.\n",
    "                if i % 4 != 0:\n",
    "                    masks[i] = np.ones_like(m)\n",
    "        else:\n",
    "            # vanilla ANN; create all masks with `ones`\n",
    "            for i, m in enumerate(masks):\n",
    "                masks[i] = np.ones_like(m)\n",
    "\n",
    "    # dendritic or sparse all-to-all\n",
    "    if input_sample == 'all_to_all':\n",
    "        for i, m in enumerate(masks):\n",
    "            # `4` denotes the number of masks per dendrosomatic layer\n",
    "            # So, elements 0, 4, 8, 12, etc will take masks filled with ones.\n",
    "            if i % 4 == 0:\n",
    "                masks[i] = np.ones_like(m)\n",
    "\n",
    "    # Add two masks for the output layer (weights and biases) set to 1.\n",
    "    masks.append(np.ones((masks[-2].shape[1], num_classes)).astype('int'))\n",
    "    masks.append(np.ones((num_classes, )).astype('int'))\n",
    "\n",
    "    return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from main import update_model_config\n",
    "from opt import get_ordered_model_names\n",
    "i, j = 1, 2\n",
    "num_dendrites = 4**i\n",
    "num_somas = 4**j\n",
    "# print(2**i,2**j)\n",
    "num_layers = 2\n",
    "synapses = 16 # doesn't do shit\n",
    "img_width = 28\n",
    "img_height = 28\n",
    "num_classes = 10\n",
    "channels = 1\n",
    "seed = 1\n",
    "\n",
    "dends = [num_dendrites]*num_layers\n",
    "somas = [num_somas]*num_layers\n",
    "\n",
    "\n",
    "m = namedtuple(\"modelConfig\", [\"conventional\", \"rfs\", \"model\", \"all_to_all\", \"sparse\"])\n",
    "m.conventional = False\n",
    "m.rfs = None\n",
    "m.all_to_all = False\n",
    "m.sparse = False\n",
    "m.model = 1\n",
    "\n",
    "update_model_config(m)\n",
    "\n",
    "name = get_ordered_model_names()[m.model]\n",
    "print(name)\n",
    "print(m.rfs)\n",
    "\n",
    "masks = make_masks_local(\n",
    "    dends, somas, synapses, num_layers, img_width, img_height, \n",
    "    num_classes, channels, m.conventional, m.sparse, m.rfs is not None, m.rfs, seed=seed\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(12):\n",
    "    m.conventional = False\n",
    "    m.rfs = None\n",
    "    m.all_to_all = False\n",
    "    m.sparse = False\n",
    "    m.model = i\n",
    "    update_model_config(m)\n",
    "    name = get_ordered_model_names()[i]\n",
    "    masks = make_masks(\n",
    "        dends, somas, synapses, num_layers, img_width, img_height, num_classes, channels, m.conventional, m.rfs is not None, m.rfs, name, seed\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv2",
   "language": "python",
   "name": ".venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
